"""
å®Œæ•´çš„å·¥ä½œæµæ¡†æ¶ - Dataclassç‰ˆæœ¬
ä¿®å¤äº†æ‰€æœ‰ç±»å‹é”™è¯¯å’Œè­¦å‘Š
"""

import asyncio
from typing import (
    Any,
    Dict,
    List,
    Optional,
    Protocol,
    Union,
    Set,
    Callable,
    runtime_checkable,
    cast,
)
from dataclasses import dataclass, field
import logging

# === ç±»å‹å®šä¹‰ ===
Action = str
Context = Dict[str, Any]
Params = Dict[str, Any]

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# === åè®®å®šä¹‰ ===
@runtime_checkable
class Node(Protocol):
    """èŠ‚ç‚¹åè®®å®šä¹‰"""

    name: str
    params: Params
    successors: Dict[Action, List["Node"]]
    id: str = field(default_factory=str)

    async def prep(self, ctx: Context) -> Any:
        """å‡†å¤‡é˜¶æ®µ - æ•°æ®é¢„å¤„ç†"""
        ...

    async def exec(self, prep_res: Any) -> Any:
        """æ‰§è¡Œé˜¶æ®µ - æ ¸å¿ƒé€»è¾‘"""
        ...

    async def post(
        self, ctx: Context, prep_res: Any, exec_res: Any
    ) -> tuple[Context, List["Node"]]:
        """åå¤„ç†é˜¶æ®µ - è¿”å›æ–°ä¸Šä¸‹æ–‡å’Œåç»­èŠ‚ç‚¹"""
        ...

    def get_next_nodes(self, action: Action) -> List["Node"]:
        """è·å–æŒ‡å®šåŠ¨ä½œçš„åç»­èŠ‚ç‚¹"""
        ...

    def next(self, *nodes: "Node") -> "Node":
        """è®¾ç½®é»˜è®¤åç»­èŠ‚ç‚¹ï¼Œè¿”å›ç¬¬ä¸€ä¸ªèŠ‚ç‚¹æˆ–self"""
        ...

    def on(self, action: Action, *nodes: "Node") -> "Node":
        """ä¸ºæŒ‡å®šåŠ¨ä½œè®¾ç½®åç»­èŠ‚ç‚¹"""
        ...

    def set_params(self, params: Params) -> "Node":
        """è®¾ç½®èŠ‚ç‚¹å‚æ•°"""
        ...


# === åŸºç¡€èŠ‚ç‚¹æ•°æ®ç±» ===
@dataclass
class BaseNode:
    """åŸºç¡€èŠ‚ç‚¹æ•°æ®ç±»"""

    name: str = ""
    params: Params = field(default_factory=dict)
    successors: Dict[Action, List["Node"]] = field(default_factory=dict)

    def __post_init__(self):
        if not self.name:
            self.name = self.__class__.__name__

    def get_next_nodes(self, action: Action) -> List["Node"]:
        """è·å–æŒ‡å®šåŠ¨ä½œçš„åç»­èŠ‚ç‚¹"""
        return self.successors.get(action, [])

    def next(self, *nodes: "Node") -> "Node":
        """è®¾ç½®é»˜è®¤åç»­èŠ‚ç‚¹"""
        self.successors["default"] = list(nodes)
        return self  # type: ignore

    def on(self, action: Action, *nodes: "Node") -> "Node":
        """ä¸ºæŒ‡å®šåŠ¨ä½œè®¾ç½®åç»­èŠ‚ç‚¹"""
        self.successors[action] = list(nodes)
        return self  # type: ignore

    def set_params(self, params: Params) -> "Node":
        """è®¾ç½®èŠ‚ç‚¹å‚æ•°"""
        self.params = params
        return self  # type: ignore

    def __repr__(self) -> str:
        return f"{self.__class__.__name__}(name='{self.name}')"


# === æ ‡å‡†èŠ‚ç‚¹å®ç° ===
@dataclass
class StandardNode(BaseNode):
    """æ ‡å‡†èŠ‚ç‚¹å®ç° - æ”¯æŒé‡è¯•å’Œå›é€€"""

    retries: int = 1
    wait_sec: float = 0.0

    async def prep(self, ctx: Context) -> Any:
        """é»˜è®¤å‡†å¤‡ - å¯ä»¥è¢«å­ç±»é‡å†™"""
        return ctx.get("data")

    async def exec(self, prep_res: Any) -> Any:
        """é»˜è®¤æ‰§è¡Œ - åº”è¯¥è¢«å­ç±»é‡å†™"""
        logger.info(f"æ‰§è¡ŒèŠ‚ç‚¹: {self.name}")
        return prep_res

    async def exec_with_retry(self, prep_res: Any) -> Any:
        """å¸¦é‡è¯•çš„æ‰§è¡Œ"""
        last_exception = None
        for i in range(self.retries):
            try:
                return await self.exec(prep_res)
            except Exception as e:
                last_exception = e
                logger.warning(
                    f"èŠ‚ç‚¹ {self.name} æ‰§è¡Œå¤±è´¥ (å°è¯• {i + 1}/{self.retries}): {e}"
                )
                if i < self.retries - 1 and self.wait_sec > 0:
                    await asyncio.sleep(self.wait_sec)

        if last_exception is not None:
            return await self.fallback(prep_res, last_exception)
        return prep_res

    async def fallback(self, prep_res: Any, error: Exception) -> Any:
        """å›é€€å¤„ç† - å¯ä»¥è¢«å­ç±»é‡å†™"""
        logger.error(f"èŠ‚ç‚¹ {self.name} æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œæ‰§è¡Œå›é€€")
        raise error

    async def post(
        self, ctx: Context, prep_res: Any, exec_res: Any
    ) -> tuple[Context, List[Node]]:
        """é»˜è®¤åå¤„ç†"""
        new_ctx = ctx.copy()
        new_ctx["data"] = exec_res
        next_nodes = self.get_next_nodes("default")
        return new_ctx, next_nodes


# === æ¡ä»¶åˆ†æ”¯èŠ‚ç‚¹ ===
@dataclass
class ConditionalNode(StandardNode):
    """æ¡ä»¶åˆ†æ”¯èŠ‚ç‚¹"""

    async def post(
        self, ctx: Context, prep_res: Any, exec_res: Any
    ) -> tuple[Context, List[Node]]:
        if await self.should_branch_true(ctx, prep_res, exec_res):
            next_nodes = self.get_next_nodes("true")
            logger.info(f"æ¡ä»¶èŠ‚ç‚¹ {self.name} èµ° true åˆ†æ”¯")
        else:
            next_nodes = self.get_next_nodes("false")
            logger.info(f"æ¡ä»¶èŠ‚ç‚¹ {self.name} èµ° false åˆ†æ”¯")

        new_ctx = ctx.copy()
        new_ctx["data"] = exec_res
        return new_ctx, next_nodes

    async def should_branch_true(
        self, ctx: Context, prep_res: Any, exec_res: Any
    ) -> bool:
        """åˆ¤æ–­åˆ†æ”¯æ¡ä»¶ - å­ç±»éœ€è¦é‡å†™"""
        return True

    def if_true(self, *nodes: "Node") -> "Node":
        """è®¾ç½®trueåˆ†æ”¯"""
        return self.on("true", *nodes)

    def if_false(self, *nodes: "Node") -> "Node":
        """è®¾ç½®falseåˆ†æ”¯"""
        return self.on("false", *nodes)


# === å¹¶è¡Œåˆ†å‰²èŠ‚ç‚¹ ===
@dataclass
class ParallelSplitNode(StandardNode):
    """å¹¶è¡Œåˆ†å‰²èŠ‚ç‚¹"""

    async def post(
        self, ctx: Context, prep_res: Any, exec_res: Any
    ) -> tuple[Context, List[Node]]:
        parallel_branches = self.get_next_nodes("parallel")
        if not parallel_branches:
            parallel_branches = self.get_next_nodes("default")

        logger.info(f"å¹¶è¡ŒèŠ‚ç‚¹ {self.name} å¯åŠ¨ {len(parallel_branches)} ä¸ªåˆ†æ”¯")
        new_ctx = ctx.copy()
        new_ctx["data"] = exec_res
        return new_ctx, parallel_branches

    def parallel(self, *nodes: "Node") -> "Node":
        """è®¾ç½®å¹¶è¡Œåˆ†æ”¯"""
        return self.on("parallel", *nodes)


# === åˆå¹¶èŠ‚ç‚¹ ===
@dataclass
class MergeNode(StandardNode):
    """åˆå¹¶èŠ‚ç‚¹ - ç­‰å¾…å¤šä¸ªåˆ†æ”¯å®Œæˆ"""

    expected_inputs: int = 1
    received_contexts: List[Context] = field(default_factory=list, init=False)
    _lock: asyncio.Lock = field(default_factory=asyncio.Lock, init=False)

    async def prep(self, ctx: Context) -> Any:
        async with self._lock:
            self.received_contexts.append(ctx)
            logger.info(
                f"åˆå¹¶èŠ‚ç‚¹ {self.name} æ”¶åˆ°è¾“å…¥ {len(self.received_contexts)}/{self.expected_inputs}"
            )
            return self.received_contexts.copy()

    async def post(
        self, ctx: Context, prep_res: Any, exec_res: Any
    ) -> tuple[Context, List[Node]]:
        async with self._lock:
            if len(self.received_contexts) < self.expected_inputs:
                logger.info(f"åˆå¹¶èŠ‚ç‚¹ {self.name} ç­‰å¾…æ›´å¤šè¾“å…¥")
                return ctx, []  # æš‚åœæ‰§è¡Œ

            # åˆå¹¶æ‰€æœ‰ä¸Šä¸‹æ–‡
            merged_context = await self.merge_contexts(self.received_contexts)
            next_nodes = self.get_next_nodes("default")

            # é‡ç½®çŠ¶æ€
            self.received_contexts = []
            logger.info(f"åˆå¹¶èŠ‚ç‚¹ {self.name} å®Œæˆåˆå¹¶ï¼Œç»§ç»­æ‰§è¡Œ")

            return merged_context, next_nodes

    async def merge_contexts(self, contexts: List[Context]) -> Context:
        """åˆå¹¶ä¸Šä¸‹æ–‡ - å¯ä»¥è¢«å­ç±»é‡å†™"""
        merged = {}
        for ctx in contexts:
            merged.update(ctx)
        return merged


# === å¾ªç¯èŠ‚ç‚¹ ===
@dataclass
class LoopNode(StandardNode):
    """å¾ªç¯èŠ‚ç‚¹"""

    max_iterations: int = 10
    current_iteration: int = field(default=0, init=False)

    async def post(
        self, ctx: Context, prep_res: Any, exec_res: Any
    ) -> tuple[Context, List[Node]]:
        self.current_iteration += 1

        if (
            self.current_iteration < self.max_iterations
            and await self.should_continue_loop(ctx, prep_res, exec_res)
        ):
            loop_nodes = self.get_next_nodes("loop")
            logger.info(
                f"å¾ªç¯èŠ‚ç‚¹ {self.name} ç»§ç»­å¾ªç¯ (ç¬¬ {self.current_iteration} æ¬¡)"
            )
            new_ctx = ctx.copy()
            new_ctx["data"] = exec_res
            return new_ctx, loop_nodes
        else:
            self.current_iteration = 0
            exit_nodes = self.get_next_nodes("exit")
            logger.info(f"å¾ªç¯èŠ‚ç‚¹ {self.name} é€€å‡ºå¾ªç¯")
            new_ctx = ctx.copy()
            new_ctx["data"] = exec_res
            return new_ctx, exit_nodes

    async def should_continue_loop(
        self, ctx: Context, prep_res: Any, exec_res: Any
    ) -> bool:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­å¾ªç¯ - å­ç±»éœ€è¦é‡å†™"""
        return False

    def loop_to(self, *nodes: "Node") -> "Node":
        """è®¾ç½®å¾ªç¯ç›®æ ‡"""
        return self.on("loop", *nodes)

    def exit_to(self, *nodes: "Node") -> "Node":
        """è®¾ç½®é€€å‡ºç›®æ ‡"""
        return self.on("exit", *nodes)


# === å¹¶è¡Œæ‰¹é‡å¤„ç†èŠ‚ç‚¹ ===
@dataclass
class ParallelBatchNode(StandardNode):
    """å¹¶è¡Œæ‰¹é‡å¤„ç†èŠ‚ç‚¹"""

    async def exec(self, prep_res: Any) -> List[Any]:
        if not isinstance(prep_res, list):
            return []

        logger.info(f"æ‰¹é‡èŠ‚ç‚¹ {self.name} å¤„ç† {len(prep_res)} ä¸ªé¡¹ç›®")
        tasks = [self.exec_item_with_retry(item) for item in prep_res]
        return await asyncio.gather(*tasks)

    async def exec_item(self, item: Any) -> Any:
        """å¤„ç†å•ä¸ªé¡¹ç›® - å­ç±»éœ€è¦é‡å†™"""
        return item

    async def exec_item_with_retry(self, item: Any) -> Any:
        """å¸¦é‡è¯•çš„å•é¡¹å¤„ç†"""
        last_exception = None
        for i in range(self.retries):
            try:
                return await self.exec_item(item)
            except Exception as e:
                last_exception = e
                if i < self.retries - 1 and self.wait_sec > 0:
                    await asyncio.sleep(self.wait_sec)
        if last_exception is not None:
            raise last_exception
        return item


# === æ‰§è¡Œå¼•æ“ ===
@dataclass
class ExecutionEngine:
    """ç»Ÿä¸€æ‰§è¡Œå¼•æ“"""

    executed_nodes: Dict[int, Any] = field(default_factory=dict, init=False)

    async def execute_nodes(
        self, start_nodes: List[Node], initial_context: Context
    ) -> Context:
        """æ‰§è¡ŒèŠ‚ç‚¹å›¾"""
        queue: List[tuple[Node, Context]] = [
            (node, initial_context.copy()) for node in start_nodes
        ]
        executed: Set[int] = set()
        final_context = initial_context.copy()

        iteration = 0
        while queue:
            iteration += 1
            logger.info(f"æ‰§è¡Œæ‰¹æ¬¡ {iteration}ï¼Œå¾…å¤„ç†èŠ‚ç‚¹: {len(queue)}")

            # å½“å‰æ‰¹æ¬¡
            current_batch: List[tuple[Node, Context]] = []
            remaining_queue: List[tuple[Node, Context]] = []

            for node, context in queue:
                node_id = id(node)
                if node_id not in executed:
                    current_batch.append((node, context))
                    executed.add(node_id)
                else:
                    remaining_queue.append((node, context))

            queue = remaining_queue

            if not current_batch:
                break

            # å¹¶è¡Œæ‰§è¡Œå½“å‰æ‰¹æ¬¡
            tasks = [
                self.execute_single_node(node, context)
                for node, context in current_batch
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # å¤„ç†ç»“æœ
            for (node, _), result in zip(current_batch, results):
                if isinstance(result, Exception):
                    logger.error(f"èŠ‚ç‚¹ {node.name} æ‰§è¡Œå¤±è´¥: {result}")
                    continue

                # ç±»å‹å®ˆå«ï¼šæ­¤æ—¶ result ä¸€å®šæ˜¯ tuple[Context, List[Node]]
                result_context, next_nodes = cast(tuple[Context, List[Node]], result)
                final_context.update(result_context)

                # æ·»åŠ åç»­èŠ‚ç‚¹åˆ°é˜Ÿåˆ—
                for next_node in next_nodes:
                    queue.append((next_node, result_context.copy()))

        logger.info(f"æ‰§è¡Œå®Œæˆï¼Œæ€»å…± {iteration} ä¸ªæ‰¹æ¬¡")
        return final_context

    async def execute_single_node(
        self, node: Node, context: Context
    ) -> tuple[Context, List[Node]]:
        """æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹"""
        logger.info(f"å¼€å§‹æ‰§è¡ŒèŠ‚ç‚¹: {node.name}")

        prep_res = await node.prep(context)

        if isinstance(node, StandardNode):
            exec_res = await node.exec_with_retry(prep_res)
        else:
            exec_res = await node.exec(prep_res)

        result = await node.post(context, prep_res, exec_res)
        logger.info(f"èŠ‚ç‚¹ {node.name} æ‰§è¡Œå®Œæˆ")
        return result


# === Flow API ===
@dataclass
class FlowAPI:
    """ç®€å•çš„æµå¼API"""

    _engine: ExecutionEngine = field(default_factory=ExecutionEngine, init=False)

    async def run(self, start_node: Node, initial_context: Context) -> Context:
        """è¿è¡Œç®€å•æµç¨‹"""
        logger.info("ä½¿ç”¨ Flow API æ‰§è¡Œ")
        return await self._engine.execute_nodes([start_node], initial_context)


# === Graph API ===
@dataclass
class GraphBuilder:
    """å›¾æ„å»ºå™¨"""

    _nodes: List[Node] = field(default_factory=list, init=False)
    _start_nodes: List[Node] = field(default_factory=list, init=False)
    _engine: ExecutionEngine = field(default_factory=ExecutionEngine, init=False)

    def add_node(self, node: Node) -> "GraphBuilder":
        """æ·»åŠ èŠ‚ç‚¹"""
        if node not in self._nodes:
            self._nodes.append(node)
        return self

    def add_edge(
        self, from_node: Node, to_node: Node, action: str = "default"
    ) -> "GraphBuilder":
        """æ·»åŠ è¾¹"""
        self.add_node(from_node).add_node(to_node)
        from_node.on(action, to_node)
        return self

    def add_conditional_edge(
        self, from_node: Node, edge_map: Dict[str, Node]
    ) -> "GraphBuilder":
        """æ·»åŠ æ¡ä»¶è¾¹"""
        self.add_node(from_node)
        for action, to_node in edge_map.items():
            self.add_node(to_node)
            from_node.on(action, to_node)
        return self

    def set_start_nodes(self, *nodes: Node) -> "GraphBuilder":
        """è®¾ç½®èµ·å§‹èŠ‚ç‚¹"""
        self._start_nodes = list(nodes)
        for node in nodes:
            self.add_node(node)
        return self

    async def run(
        self,
        start_nodes: Union[Node, List[Node], None] = None,
        initial_context: Optional[Context] = None,
    ) -> Context:
        """è¿è¡Œå›¾"""
        if start_nodes is None:
            start_nodes = self._start_nodes
        elif isinstance(start_nodes, Node):
            start_nodes = [start_nodes]

        if not start_nodes:
            raise ValueError("å¿…é¡»æŒ‡å®šèµ·å§‹èŠ‚ç‚¹")

        if initial_context is None:
            initial_context = {}

        logger.info("ä½¿ç”¨ Graph API æ‰§è¡Œ")
        return await self._engine.execute_nodes(start_nodes, initial_context)


# === ç»Ÿä¸€æ¡†æ¶å…¥å£ ===
@dataclass
class WorkflowFramework:
    """ç»Ÿä¸€å·¥ä½œæµæ¡†æ¶"""

    flow: FlowAPI = field(default_factory=FlowAPI, init=False)

    # === ç®€å•ç”¨æ³• ===
    async def run_flow(self, start_node: Node, context: Context) -> Context:
        """è¿è¡Œç®€å•æµç¨‹"""
        return await self.flow.run(start_node, context)

    # === é«˜çº§ç”¨æ³• ===
    def create_graph(self) -> GraphBuilder:
        """åˆ›å»ºå›¾æ„å»ºå™¨"""
        return GraphBuilder()

    # === æ™ºèƒ½ç”¨æ³• ===
    async def run_auto(self, start_node: Node, context: Context) -> Context:
        """æ™ºèƒ½æ‰§è¡Œ - è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ–¹å¼"""
        return await self.run_flow(start_node, context)


# === å®ç”¨èŠ‚ç‚¹å®ç° ===
@dataclass
class FunctionNode(StandardNode):
    """å‡½æ•°èŠ‚ç‚¹ - åŒ…è£…æ™®é€šå‡½æ•°"""

    func: Callable[[Any], Any] = field(default=lambda x: x)

    async def exec(self, prep_res: Any) -> Any:
        if asyncio.iscoroutinefunction(self.func):
            return await self.func(prep_res)
        else:
            return self.func(prep_res)


@dataclass
class DataTransformNode(StandardNode):
    """æ•°æ®è½¬æ¢èŠ‚ç‚¹"""

    transform_func: Callable[[Any], Any] = field(default=lambda x: x)

    async def exec(self, prep_res: Any) -> Any:
        return self.transform_func(prep_res)


@dataclass
class PrintNode(StandardNode):
    """æ‰“å°èŠ‚ç‚¹ - ç”¨äºè°ƒè¯•"""

    prefix: str = ""

    async def exec(self, prep_res: Any) -> Any:
        print(f"{self.prefix}{prep_res}")
        return prep_res


# === æµ‹è¯•ç”¨ä¾‹å’Œç¤ºä¾‹ ===
async def test_simple_flow():
    """æµ‹è¯•ç®€å•æµç¨‹"""
    print("\n=== æµ‹è¯•ç®€å•æµç¨‹ ===")

    framework = WorkflowFramework()

    # åˆ›å»ºèŠ‚ç‚¹
    node1 = FunctionNode(name="æ­¥éª¤1", func=lambda x: f"{x}_step1")
    node2 = FunctionNode(name="æ­¥éª¤2", func=lambda x: f"{x}_step2")
    node3 = PrintNode(name="æ‰“å°", prefix="æœ€ç»ˆç»“æœ: ")

    # æ„å»ºé“¾
    node1.next(node2)
    node2.next(node3)

    # æ‰§è¡Œ
    result = await framework.run_flow(node1, {"data": "å¼€å§‹"})
    print("Flow æ‰§è¡Œç»“æœ:", result)


async def test_conditional_flow():
    """æµ‹è¯•æ¡ä»¶åˆ†æ”¯"""
    print("\n=== æµ‹è¯•æ¡ä»¶åˆ†æ”¯ ===")

    @dataclass
    class NumberCheckNode(ConditionalNode):
        async def should_branch_true(
            self, ctx: Context, prep_res: Any, exec_res: Any
        ) -> bool:
            return isinstance(prep_res, int) and prep_res > 5

    framework = WorkflowFramework()

    checker = NumberCheckNode(name="æ•°å­—æ£€æŸ¥")
    big_handler = FunctionNode(name="å¤§æ•°å¤„ç†", func=lambda x: f"å¤§æ•°: {x}")
    small_handler = FunctionNode(name="å°æ•°å¤„ç†", func=lambda x: f"å°æ•°: {x}")
    final = PrintNode(name="æœ€ç»ˆ", prefix="æ¡ä»¶åˆ†æ”¯ç»“æœ: ")

    # æ„å»ºåˆ†æ”¯
    checker.if_true(big_handler)
    checker.if_false(small_handler)
    big_handler.next(final)
    small_handler.next(final)

    # æµ‹è¯•å¤§æ•°
    result1 = await framework.run_flow(checker, {"data": 10})
    print("å¤§æ•°ç»“æœ:", result1)

    # æµ‹è¯•å°æ•°
    result2 = await framework.run_flow(checker, {"data": 3})
    print("å°æ•°ç»“æœ:", result2)


async def test_parallel_flow():
    """æµ‹è¯•å¹¶è¡Œæµç¨‹"""
    print("\n=== æµ‹è¯•å¹¶è¡Œæµç¨‹ ===")

    framework = WorkflowFramework()

    # åˆ›å»ºå›¾
    graph = framework.create_graph()

    start = FunctionNode(name="å¼€å§‹", func=lambda x: x)
    branch1 = FunctionNode(name="åˆ†æ”¯1", func=lambda x: f"{x}_branch1")
    branch2 = FunctionNode(name="åˆ†æ”¯2", func=lambda x: f"{x}_branch2")
    merge = MergeNode(name="åˆå¹¶", expected_inputs=2)
    end = PrintNode(name="ç»“æŸ", prefix="å¹¶è¡Œç»“æœ: ")

    # æ„å»ºå›¾ç»“æ„
    (
        graph.add_edge(start, branch1)
        .add_edge(start, branch2)
        .add_edge(branch1, merge)
        .add_edge(branch2, merge)
        .add_edge(merge, end)
    )

    result = await graph.run(start, {"data": "å¹¶è¡Œå¼€å§‹"})
    print("å¹¶è¡Œæ‰§è¡Œç»“æœ:", result)


async def test_complex_graph():
    """æµ‹è¯•å¤æ‚å›¾ç»“æ„"""
    print("\n=== æµ‹è¯•å¤æ‚å›¾ç»“æ„ ===")

    @dataclass
    class LoopCounterNode(LoopNode):
        max_count: int = 3
        counter: int = field(default=0, init=False)

        def __post_init__(self):
            super().__post_init__()
            self.max_iterations = self.max_count

        async def exec(self, prep_res: Any) -> Any:
            self.counter += 1
            return f"{prep_res}_loop{self.counter}"

        async def should_continue_loop(
            self, ctx: Context, prep_res: Any, exec_res: Any
        ) -> bool:
            return self.counter < 3

    framework = WorkflowFramework()
    graph = framework.create_graph()

    start = FunctionNode(name="å¼€å§‹", func=lambda x: "start")
    loop_node = LoopCounterNode(name="å¾ªç¯èŠ‚ç‚¹", max_count=3)
    process = FunctionNode(name="å¤„ç†", func=lambda x: f"{x}_processed")
    end = PrintNode(name="ç»“æŸ", prefix="å¤æ‚å›¾ç»“æœ: ")

    # æ„å»ºå¾ªç¯ç»“æ„
    loop_node.loop_to(process)
    loop_node.exit_to(end)
    process.next(loop_node)  # å½¢æˆå¾ªç¯

    (graph.add_edge(start, loop_node).set_start_nodes(start))

    result = await graph.run(initial_context={"data": "å¤æ‚å¼€å§‹"})
    print("å¤æ‚å›¾æ‰§è¡Œç»“æœ:", result)


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•å·¥ä½œæµæ¡†æ¶")

    try:
        await test_simple_flow()
        await test_conditional_flow()
        await test_parallel_flow()
        await test_complex_graph()

        print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
